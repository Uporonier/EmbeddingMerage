from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
import torch.nn as nn
import torch.nn.functional as F
from tqdm.auto import tqdm
import os

# ==================== 配置 ====================
class Config:
    # 模型路径（根据实际修改）
    model_A_path = '/content/EmbeddingMerage/models/llama-1b'  # 1B模型
    model_B_path = '/content/EmbeddingMerage/models/llama-3b'  # 3B模型
    projector_path = 'best_projector.pt'  # 预训练投影层权重路径
    output_path = '/content/merged_model'  # 融合后模型保存路径
    
    # 融合参数
    alpha = 0.3  # 可自由调整的融合系数（0-1之间）

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# ==================== 投影层定义（需与训练时一致）====================
class TokenProjector(nn.Module):
    def __init__(self, in_dim, out_dim):
        super().__init__()
        self.proj = nn.Sequential(
            nn.Linear(in_dim, out_dim * 2),
            nn.GELU(),
            nn.LayerNorm(out_dim * 2),
            nn.Linear(out_dim * 2, out_dim),
            nn.LayerNorm(out_dim)
        )

    def forward(self, x):
        return F.normalize(self.proj(x), dim=-1, eps=1e-8)

# ==================== 主流程 ====================
def main():
    # 1. 加载模型和分词器
    print("Loading models...")
    model_A = AutoModelForCausalLM.from_pretrained(
        Config.model_A_path,
        device_map="auto",
        torch_dtype=torch.float16
    )
    model_B = AutoModelForCausalLM.from_pretrained(
        Config.model_B_path,
        device_map="auto",
        torch_dtype=torch.float16
    )
    tokenizer = AutoTokenizer.from_pretrained(Config.model_A_path)

    # 2. 提取原始embedding
    def get_embeddings(model):
        emb = model.model.embed_tokens.weight.data.clone()
        emb = emb.to(device).float()  # 统一转为float32处理
        return F.normalize(emb, p=2, dim=1)
    
    print("Extracting embeddings...")
    embeddings_A = get_embeddings(model_A)
    embeddings_B = get_embeddings(model_B)
    assert embeddings_A.shape[0] == embeddings_B.shape[0], "词表大小不匹配!"

    # 3. 初始化并加载投影层
    print(f"Loading projector from {Config.projector_path}...")
    projector = TokenProjector(
        in_dim=embeddings_B.size(1),
        out_dim=embeddings_A.size(1)
    ).to(device)
    projector.load_state_dict(torch.load(Config.projector_path))
    projector.eval()

    # 4. 投影和融合
    print("Projecting and merging embeddings...")
    with torch.no_grad():
        # 投影3B的embedding到1B空间
        projected_B = projector(embeddings_B)
        
        # 加权融合 (alpha=1: 完全用1B; alpha=0: 完全用3B投影结果)
        combined_emb = Config.alpha * embeddings_A + (1 - Config.alpha) * projected_B
        combined_emb = F.normalize(combined_emb, p=2, dim=1)
        
        # 检查数值有效性
        assert not torch.isnan(combined_emb).any(), "融合结果包含NaN!"
        
        # 更新1B模型的embedding层
        model_A.model.embed_tokens.weight = nn.Parameter(combined_emb.to(torch.float16))

    # 5. 保存融合后的模型
    print(f"Saving merged model to {Config.output_path}...")
    model_A.save_pretrained(Config.output_path)
    tokenizer.save_pretrained(Config.output_path)
    
    print("Done! 融合系数 alpha =", Config.alpha)

if __name__ == "__main__":
    main()